{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "import re\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.read_csv('Resources/filtered_psalms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts):\n",
    "    response = openai.embeddings.create(\n",
    "        input=texts,\n",
    "        model=\"text-embedding-3-small\"  # or any other appropriate model\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Get embeddings for the queries in filtered_df\n",
    "res = get_embeddings(filtered_df['query'])\n",
    "res2 = get_embeddings(filtered_df['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['query_embeddings']=[e.embedding for e in res.data]\n",
    "filtered_df['verse_embeddings']=[e.embedding for e in res2.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in filtered_df.iterrows(): \n",
    "    filtered_df.loc[idx, 'score']=distance.euclidean(filtered_df.loc[idx, 'query_embeddings'], filtered_df.loc[idx, 'verse_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def find_best_verses(user_query):\n",
    "    uqe = get_embeddings(user_query).data[0].embedding\n",
    "    scores = []\n",
    "    \n",
    "    for i, row in filtered_df.iterrows():\n",
    "        dist = distance.euclidean(row[\"query_embeddings\"], uqe)\n",
    "        scores.append((dist, i))\n",
    "    \n",
    "    # Sort by distance and select the top 5 matches\n",
    "    scores = sorted(scores, key=lambda x: x[0])[:5]  # Sort by distance (ascending)\n",
    "\n",
    "    # Collect the best matching verses\n",
    "    best_verses = [\n",
    "        f\"{i + 1}. {filtered_df.iloc[index]['t']}\" for i, (_, index) in enumerate(scores)\n",
    "    ]\n",
    "\n",
    "    # Format the output as a string\n",
    "    verses_str =  \"\\n\".join(best_verses)\n",
    "    \n",
    "    # Evaluate relevance using LangChain\n",
    "    evaluation, yes_ratio = evaluate_relevance(user_query, verses_str)\n",
    "\n",
    "    # Return both the verses, evaluation result, and yes ratio\n",
    "    return f\"Best Verses:\\n{verses_str}\\n\\nEvaluation:\\n{evaluation}\\n\\nYes Ratio: {yes_ratio:.2%}\"\n",
    "\n",
    "def evaluate_relevance(user_query, verses):\n",
    "    # Define the evaluation prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"verses\"],\n",
    "        template=(\n",
    "            \"Given the query: '{query}' and the following verses:\\n\\n\"\n",
    "            \"{verses}\\n\\n\"\n",
    "            \"Rate each verse with either a yes or no, yes being relevant advice and no being irrelevant advice to the query. Also give a brief explanation why you chose your answer.\"\n",
    "            \"Format your answers exactly as:\\n\"\n",
    "            \"1. yes\\n\"\n",
    "            \"2. no\\n\"\n",
    "            \"3. yes\\n\"\n",
    "            \"Provide brief explanations below the answers.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Format the prompt with the user's query and verses\n",
    "    formatted_prompt = prompt.format(query=user_query, verses=verses)\n",
    "\n",
    "    # Use LangChain to generate an evaluation\n",
    "    messages = [HumanMessage(content=formatted_prompt)]\n",
    "    response = llm(messages).content\n",
    "    \n",
    "    answers = re.findall(r\"\\b(yes|no)\\b\", response.lower())\n",
    "\n",
    "    # Calculate the ratio of 'yes' answers\n",
    "    yes_count = answers.count(\"yes\")\n",
    "    total_count = len(answers)\n",
    "    yes_ratio = yes_count / total_count if total_count > 0 else 0\n",
    "\n",
    "    # Return the response and yes ratio\n",
    "    return response, yes_ratio\n",
    "\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Interface(\n",
    "    fn=find_best_verses,                       # Function to handle input\n",
    "    inputs=gr.Textbox(label=\"What would you like to seek advice about?\"),  # Input box\n",
    "    outputs=\"text\",                      # Output displayed as text\n",
    "    title=\"Advice Seeker\",               # Title of the app\n",
    "    description=\"Enter a topic you need advice on, and we will return the top 5 bible verses to help you with your problems.\"  # Brief description\n",
    ") as interface:\n",
    "    interface.launch()  # Launch the Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to track total responses and yes counts\n",
    "total_ratio = 0\n",
    "\n",
    "example_queries = [\"How can I cope with stress during tough times?\",\n",
    "                  \"What should I consider when making a big life decision?\",\n",
    "                  \"How can I rebuild trust with a friend after a conflict?\",\n",
    "                  \"What can I do to overcome my fears?\",\n",
    "                  \"How can I manage my anger in difficult situations?\",\n",
    "                  \"What are some strategies to stay motivated at work?\",\n",
    "                  \"What techniques can help me reduce anxiety?\",\n",
    "                  \"How can I boost my self-confidence?\",\n",
    "                  \"What practices can help me feel more grateful?\",\n",
    "                  \"What are effective ways to resolve disagreements with others?\"]\n",
    "\n",
    "\n",
    "# Initialize variables to track total responses and yes counts\n",
    "total_ratio = 0\n",
    "\n",
    "# Loop through each query\n",
    "for query in example_queries:\n",
    "    # Call the find_best_verses function to get verses and evaluation\n",
    "    output = find_best_verses(query)\n",
    "    \n",
    "    # Extract the evaluation part from the output\n",
    "    evaluation = output.split(\"\\n\\nEvaluation:\\n\")[1]\n",
    "    yes_ratio = float(evaluation[-6:-1])\n",
    "    # Count the 'yes' and 'no' responses\n",
    "    responses = evaluation.splitlines()\n",
    "    total_ratio += yes_ratio\n",
    "print(total_ratio)\n",
    "    # Count total responses (assuming each query should have 5 responses)\n",
    "\n",
    "# Calculate the yes ratio\n",
    "total_ratio /= 10\n",
    "yes_numbers = total_ratio*.5\n",
    "no_numbers = 50-yes_numbers\n",
    "\n",
    "# Print the results\n",
    "print(f\"'Yes' Ratio: {total_ratio:.2f}\")\n",
    "print(f\"'Yes' numbers: {yes_numbers:.2f}\")\n",
    "print(f\"'No' numbers: {no_numbers:.2f}\")\n",
    "\n",
    "# Calculate the yes ratio\n",
    "total_ratio /= 100\n",
    "yes_numbers = total_ratio*5\n",
    "no_numbers = 500-yes_numbers\n",
    "\n",
    "# Print the results\n",
    "print(f\"'Yes' Ratio: {total_ratio:.2f}\")\n",
    "print(f\"'Yes' numbers: {yes_numbers:.2f}\")\n",
    "print(f\"'No' numbers: {no_numbers:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
